## ğŸ”‘ **PRT(Peer Review Template)**

- [ ]  **1. ì£¼ì–´ì§„ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì™„ì„±ëœ ì½”ë“œê°€ ì œì¶œë˜ì—ˆë‚˜ìš”? (ì™„ì„±ë„)**
    - ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ìµœì¢… ê²°ê³¼ë¬¼ì´ ì²¨ë¶€ë˜ì—ˆëŠ”ì§€ í™•ì¸
    - [x] ì¸ë¬¼ ëª¨ë“œ ì‚¬ì§„ êµ¬í˜„
        ![ì¸ë¬¼ëª¨ë“œ](./reviewimg/person.png)
    - [ ] ì¸ë¬¼ ëª¨ë“œ ë¬¸ì œì  ì‚¬ì§„
    - [x] ì¸ë¬¼ëª¨ë“œ ì‚¬ì§„ì˜ ë¬¸ì œì ì„ ê°œì„ í•  ìˆ˜ ìˆëŠ” ì†”ë£¨ì…˜ ì œì‹œ
        ![ì†”ë£¨ì…˜](./reviewimg/solution.png)

- [x]  **2. í”„ë¡œì íŠ¸ì—ì„œ í•µì‹¬ì ì¸ ë¶€ë¶„ì— ëŒ€í•œ ì„¤ëª…ì´ ì£¼ì„(ë‹¥ìŠ¤íŠ¸ë§) ë° ë§ˆí¬ë‹¤ìš´ í˜•íƒœë¡œ ì˜ ê¸°ë¡ë˜ì–´ìˆë‚˜ìš”? (ì„¤ëª…)**
    - [x] ê¸°ëŠ¥ì„ í•¨ìˆ˜ë¡œ ì ì ˆíˆ ë¶„í• í•˜ì—¬ êµ¬í˜„í–ˆê³  ê°€ë…ì„±ì´ ì¢‹ì€ ê°„ê²°í•œ ì£¼ì„ì„ ê¸°ë¡í•˜ì˜€ìŠµë‹ˆë‹¤.
        ![ì£¼ì„](./reviewimg/annotation.png)

- [ ]  **3. ì²´í¬ë¦¬ìŠ¤íŠ¸ì— í•´ë‹¹í•˜ëŠ” í•­ëª©ë“¤ì„ ëª¨ë‘ ìˆ˜í–‰í•˜ì˜€ë‚˜ìš”? (ë¬¸ì œ í•´ê²°)**
    - [ ]  ë°ì´í„°ë¥¼ ë¶„í• í•˜ì—¬ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í–ˆë‚˜ìš”? (train, validation, test ë°ì´í„°ë¡œ êµ¬ë¶„)
    - [ ]  í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ë³€ê²½í•´ê°€ë©° ì—¬ëŸ¬ ì‹œë„ë¥¼ í–ˆë‚˜ìš”? (learning rate, dropout rate, unit, batch size, epoch ë“±)
    - [x]  ê° ì‹¤í—˜ì„ ì‹œê°í™”í•˜ì—¬ ë¹„êµí•˜ì˜€ë‚˜ìš”?
        ![ì‹¤í—˜](./reviewimg/experiment.png)
    - [ ]  ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ê°€ ê¸°ë¡ë˜ì—ˆë‚˜ìš”?

- [ ]  **4. í”„ë¡œì íŠ¸ì— ëŒ€í•œ íšŒê³ ê°€ ìƒì„¸íˆ ê¸°ë¡ ë˜ì–´ ìˆë‚˜ìš”? (íšŒê³ , ì •ë¦¬)**
    - [ ]  ë°°ìš´ ì 
    - [ ]  ì•„ì‰¬ìš´ ì 
    - [ ]  ëŠë‚€ ì 
    - [ ]  ì–´ë ¤ì› ë˜ ì 


---

# íšŒê³ 
> convê´€ë ¨ ë°°ìš´ì  ìš”ì•½


## ëŠë‚€ì  / ì•„ì‰¬ìš´ì 

- Depthwise separable convolutionì—ì„œ í—·ê°ˆë¦¬ëŠ” ë¶€ë¶„ë“¤ì„ ì •ë¦¬í•˜ë‹¤ë³´ë‹ˆ, ì‹¤í—˜ì— í¬ê²Œ í˜ì„ ìŸì§€ëŠ” ëª»í–ˆë˜ ê²ƒ ê°™ë‹¤.
- Atrous Convolutionì˜ rateë¡œ ë„ì›Œì§€ëŠ” ê³µê°„ì´ ì±„ì›Œì§€ëŠ” ì¤„ ì•Œì•˜ëŠ”ë°, ì•Œê³ ë³´ë‹ˆ ê·¸ëƒ¥ í¬ê¸°ë§Œ í‚¤ìš°ëŠ” ë°©ì‹ì´ì—ˆë‹¤.
- depth predictionì— ëŒ€í•´ì„œ ì¢€ ë” ê¹Šê²Œ íŒŒë³´ê³  ì‹¶ë‹¤ëŠ” ìƒê°ì„ í–ˆë‹¤.

## ë°°ìš´ì 
> https://minkj1992.github.io/conv/

#### Standard Conv Layer

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdiQ1OC%2FbtqF9CF0J2F%2FbXeMQ23BAHATAswUEYWuJ1%2Fimg.png)

ì¼ë°˜ì ì¸ `Conv layer`ëŠ” (3,3) ë˜ëŠ” (5,5) `kernel`ì„ ì‚¬ìš©í•˜ì—¬ ìŠ¬ë¼ì´ë”©í•˜ë©° `feature map`ì„ ìƒì„±í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì…ë ¥ì´ 128*128 í¬ê¸°ì˜ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¼ë©´ (128, 128, 3)ì˜ í˜•íƒœë¥¼ ê°€ì§‘ë‹ˆë‹¤. RGB ì±„ë„ ê°ê°ì— ëŒ€í•´ 3ê°œì˜ weight(kernel)ë¥¼ ì‚¬ìš©í•˜ì—¬ ìŠ¬ë¼ì´ë”©ì„ ì‹œí–‰í•˜ê³ , stride=1ì¸ ê²½ìš° (128 - 3 + 1, 128 - 3 + 1, 3) í¬ê¸°ì˜ output matrixë“¤ì´ ìƒì„±ë©ë‹ˆë‹¤.

![](https://www.mdpi.com/remotesensing/remotesensing-13-04712/article_deploy/html/images/remotesensing-13-04712-g003-550.jpg)


ì´ output matrixë“¤ì€ Relu activationì— ë„£ê¸° ìœ„í•´, 3ê°œì˜ output matrix (126, 126, 3)ë¥¼ ì±„ë„ ë°©í–¥ìœ¼ë¡œ ëª¨ë‘ í•©ì¹œ í›„, (126, 126) í¬ê¸°ì˜ bias matrixë¥¼ ë”í•œ ê°’ì„ Reluì— ë„£ì–´ì¤ë‹ˆë‹¤. 

ì´ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ ë‚˜íƒ€ë‚´ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

$$
\text{Relu}((\text{Conv}(I, W) + B))
$$

ì—¬ê¸°ì„œ \( I \)ëŠ” ì…ë ¥ ì´ë¯¸ì§€, \( W \)ëŠ” ì»¤ë„, \( B \)ëŠ” biasì…ë‹ˆë‹¤. ì´ë¥¼ ìˆ˜ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ë©´,

$$
\text{Relu}(\sum_{c=1}^3 \text{Conv}(I_c, W_c) + B)
$$

ì—¬ê¸°ì„œ \( I_c \)ëŠ” ê° ì±„ë„ì— ëŒ€í•œ ì…ë ¥, \( W_c \)ëŠ” ê° ì±„ë„ì— ëŒ€í•œ ì»¤ë„ì…ë‹ˆë‹¤. 
ë”°ë¼ì„œ ìµœì¢… ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

$$
\text{Relu} \left( \left( \sum_{c=1}^{3} \text{Conv}(I_c, W_c) \right) + B \right)
$$

![](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*R7wuPKS9tDjrpnW-emxdjw.jpeg)


#### Point-wise Convolution
> Convolution Layer with a 1x1 kernels

- [Andrew Ng's lecture](https://www.youtube.com/watch?v=c1RBQzKsDCk)


Point-wise convëŠ” ì»¤ë„ í¬ê¸°ê°€ 1x1ë¡œ ê³ ì •ëœ convolution Layerë¥¼ ë§í•œë‹¤. ì´ë•Œ point wise convê°€ 1x1ì´ë”ë¼ë„, kernelì˜ ì°¨ì› ìˆ˜ëŠ” input channelì„ ë”°ë¥¸ë‹¤ëŠ” ê²ƒì´ë‹¤. (ë§¤ìš° í—·ê°ˆë ¸ë˜ ê²ƒ ì¤‘ì— í•˜ë‚˜ê°€, 1x1x1ì¸ì§€ ì•„ë‹Œì§€ ì˜€ê³ , ê²°ë¡ ì€ `1 x 1 x inputchannel`ì´ë‹¤.)

Standard conv layerë„ ìƒê°í•´ë³´ë©´ input channelë“¤ì„ ëª¨ë‘ ë”í•˜ê³  bias ë”í•œë‹¤ìŒ `activation()`ì„ ì‹¤í–‰í•˜ê¸° ë•Œë¬¸ì—, standard conv layerì™€ì˜ ì°¨ì´ì ì€ `1x1` ì‚¬ì´ì¦ˆ ë§ê³ ëŠ” ì—†ë‹¤. ë‹¤ë¥¸ ë¸”ë¡œê·¸ ê¸€ì½ì–´ë³´ë©´ Dimensionality Reductionì´ë‹ˆ ë­ë‹ˆ 1x1ì˜ íŠ¹ì„±ì²˜ëŸ¼ ë§í•˜ë˜ë°, standard convë„ ì´ë¯¸ ë™ì¼í•˜ê²Œ input channelë“¤ í•©ì³ì£¼ê³  ìˆìœ¼ë‹ˆ point wiseë§Œì˜ íŠ¹ë³„í•œ featureëŠ” ì•„ë‹ˆë‹¤.

- Inputì˜ ì±„ë„ë“¤ì„ í•˜ë‚˜ë¡œ í•©ì³¤ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤. (Standard Conv layerì™€ ë™ì¼)
- 1x1ë¡œ slidingí•˜ê¸° ë•Œë¬¸ì— Spatial Featureë“¤ì€ ì¶”ì¶œí•˜ì§€ ëª»í•œë‹¤. (Standard Convì˜ kernel_size=3 ë¼ë©´ 3x3 ì˜ì—­ì—ì„œ í”½ì…€ê°„ì˜ ìƒê´€ê´€ê³„ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ)


(28,28,192)ì— ëŒ€í•´ì„œ 1x1 conv(weightê°€ 192ê°œì¸ 1x1x192)ë¥¼ í†µê³¼ì‹œí‚¤ë©´, (28 x 28) í¬ê¸°ì˜ feature mapì´ ë§Œë“¤ì–´ì§„ë‹¤. ì´ë•Œ filter ê°¯ìˆ˜ê°€ 32ê°œë¼ê³  í•œë‹¤ë©´, ì´ë¥¼ 32ë²ˆ ë°˜ë³µí•˜ì—¬, (28,28,32)ì˜ feature mapì„ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆë‹¤.

<u>ì‚¬ì‹¤ standard convì™€ ë‹¤ë¥¼ê±´ ì—†ì§€ë§Œ, standard convì™€ ë‹¬ë¦¬ heightì™€ widthê°€ ë³´ì¡´ ë˜ë©´ì„œ ì±„ë„ë§Œ ì¶•ì†Œë˜ëŠ” íš¨ê³¼ë¥¼ ê°€ì§ˆ ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ì°¨ì› ì¶•ì†Œë¥¼ ì›í•  ë•Œ 1x1ë¥¼ ìì£¼ ì‚¬ìš©í•˜ëŠ” ê²ƒ ê°™ë‹¤.</u>


- [ResNet BottleNeck ì›ë¦¬](https://coding-yoon.tistory.com/116)


#### Depth-wise Convolution
> Channel-independent Convolution

- input channelë“¤ì„ ë…ë¦½ì ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤. -> ê° ì±„ë„ë“¤ì˜ spatial Featureë¥¼ ì¶”ì¶œ í•  ìˆ˜ ìˆë‹¤.
- Depth-wise convolutionì€ ê° ë‹¨ì¼ input channelì— ëŒ€í•´ì„œë§Œ ìˆ˜í–‰ë˜ëŠ” í•„í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. 
- ì¦‰ ì´ ë•Œë¬¸ì— í•„ì—°ì ìœ¼ë¡œ, `ì…ë ¥ ì±„ë„ ìˆ˜ = í•„í„°ìˆ˜`ê°€ ë©ë‹ˆë‹¤. (=ì…ë ¥-ì¶œë ¥ ì±„ë„ì˜ ìˆ˜ê°€ ë™ì¼í•˜ë‹¤.)


![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FtLN9H%2FbtqGbbuHSfv%2FPw9c5SIy0EJdQk84Fzjlk1%2Fimg.png)



#### Depthwise separable convolution
> 'Separate Spatial feature'(depth-wise) and 'Cross channel'(point-wise) Correlation


- `Original Convolution`
    - ì „ì²´ ì±„ë„ì— ëŒ€í•œ Spatial Convolution
- `Depth-wise Separable Convolution`
    - ê° ì±„ë„ ë³„ Spatial Convolution ì´í›„(depth-wise) -> Featureë³„ Linear Combination (point-wise)

![](https://mblogthumb-phinf.pstatic.net/MjAxOTAxMDNfMjQy/MDAxNTQ2NDk1MDk0OTIx.0QF46tNJ7B3NvdEZfH6DYTMwCLTX-iescNu3XzLqmSog.4WTqAxovFZ4jLJR3YzMHv1BpbCZJOCwHDSEGPvWcZzEg.PNG.worb1605/image.png?type=w800)



#### refs

- [Designing more efficient conv nn](https://www.slideshare.net/slideshow/designing-more-efficient-convolution-neural-network-122869307/122869307)


#### ì¶•ì†Œí•˜ê³  ë³µì› ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” ì´ìœ ? (Auto Encoder)
> https://techblog-history-younghunjo1.tistory.com/130#google_vignette

> ì˜¤í† ì¸ì½”ë”ëŠ” ì…ë ¥ ë°ì´í„°ì™€ ì¬êµ¬ì„±ëœ ë°ì´í„° ì‚¬ì´ì˜ ì°¨ì´ë¥¼ ìµœì†Œí™”í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµë©ë‹ˆë‹¤. ì´ëŠ” ì˜¤í† ì¸ì½”ë”ê°€ ë°ì´í„°ì˜ ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì§•ì„ í¬ì°©í•˜ëŠ” ì••ì¶•ëœ í‘œí˜„ì„ í•™ìŠµí•˜ë ¤ê³  í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. ì˜¤í† ì¸ì½”ë”ê°€ ì´ ì••ì¶•ëœ í‘œí˜„ì—ì„œ ì…ë ¥ ë°ì´í„°ë¥¼ ì¬êµ¬ì„±í•˜ë„ë¡ ê°•ì œí•¨ìœ¼ë¡œì¨ ëª¨ë¸ì€ ë°ì´í„°ì˜ ê¸°ë³¸ êµ¬ì¡°ë¥¼ í•™ìŠµí•˜ë„ë¡ ê°•ì œë©ë‹ˆë‹¤. ì´ëŠ” ì°¨ì› ê°ì†Œ ë° ë…¸ì´ì¦ˆ ì œê±°ì™€ ê°™ì€ ì‘ì—…ì— ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì°¨ì›ì„ ì¶•ì†Œí•˜ê³  ë‹¤ì‹œ ë³µì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í•™ìŠµí•˜ëŠ” Auto encoderëŠ” Encoder-Decoder íŒ¨í„´ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì••ì¶•í•œ ë‹¤ìŒ ë³µì›í•˜ë©´ì„œ í•™ìŠµì„ í•©ë‹ˆë‹¤.

ê·¸ëƒ¥ ë°ì´í„°ë¥¼ ì••ì¶•í•˜ì§€ ì•Šê³ , ì¶œë ¥ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ë‚´ë³´ë‚¸ë‹¤ìŒ labelê°’ê³¼ lossê³„ì‚°í•˜ë©´ ë˜ëŠ”ë° êµ³ì´ ì™œ ì••ì¶•/ë³µì› ê³¼ì •ì´ í•„ìš”í•œê°€? ë¼ëŠ” ì§ˆë¬¸ì—ëŠ” 

**ìš°ë¦¬ê°€ ì›í•˜ëŠ” ê²ƒì€ ì…ë ¥ ë°ì´í„°ë¥¼ ì••ì¶•ì‹œí‚´ìœ¼ë¡œì¨ ì–»ëŠ” ë‚´ì¬ëœ(latent) ì •ë³´ë¥¼ ì–»ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.** ë˜í•œ ì••ì¶•ì„ í†µí•´ ì–‘ì´ í° ë°ì´í„°ë¥¼ ì¶•ì†Œì‹œì¼œ ì „ë‹¬í•  ìˆ˜ ìˆìœ¼ë©° ì••ì¶•ëœ ì´í›„ ë³µì›í•˜ë©´ì„œ, important featureë§Œ ë‚¨ì•„ ì¤‘ìš”í•œ í”¼ì²˜ë“¤ì´ ë” ì˜ ì‚´ì•„ìˆê¸°ë„ í•©ë‹ˆë‹¤.

ë˜í•œ ì…ë ¥ ë°ì´í„° vs ì…ë ¥->ì••ì¶•->ë³µì› ê°’ì„ ë¹„êµí•¨ìœ¼ë¡œì¨ labelì—†ì´ë„ í‰ê°€í•  ìˆ˜ ìˆëŠ” unsupervised learningì…ë‹ˆë‹¤.

ë°ì´í„°ì˜ ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì§•ì„ í¬ì°©í•˜ëŠ” ì••ì¶•ëœ í‘œí˜„ì„ í•™ìŠµ


#### Atrous Convolution 
> Atrous Convì˜ Q. ë¹ˆê³µê°„ì€ ë­ë¡œ ì±„ì›Œì§€ëŠ” ê±´ê°€? ì•ˆì±„ì›Œë„ ëœë‹¤.

- Contextual Informationì„ ë” ì˜ ë°˜ì˜í•˜ê¸° ìœ„í•´ì„œëŠ” Receptive Fieldë¥¼ í™•ì¥í•  í•„ìš”ê°€ ìˆë‹¤.
- [Atrous convolution(dilated convolution)](https://better-tomorrow.tistory.com/entry/Atrous-Convolution)

